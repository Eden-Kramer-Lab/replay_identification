# Identification and characterization of replay events Decoding for rat Bond,
# day3, epoch2

packages <- c("R.matlab", "here", "doSNOW", "multitaper", "mvtnorm",
              "splines")

package.check <- lapply(packages, FUN = function(x) {
    if (!require(x, character.only = TRUE)) {
        install.packages(x, dependencies = TRUE)
        library(x, character.only = TRUE)
    }
})

day <- 3
epoch <- 2
freq <- 500

LFP_SAMPLING_FREQUENCY <- 1500

###############################
# 1. Read and clean data
###############################

## 1.1 AR(1) fit for animal's movement during active exploration
## choose faster time rate to be 20~33 here.

by <- 1  # bin size in space
### Read animal's linearized velocity by Loren's group
position <- readMat(here("Raw-Data", "Bond",
                         paste("bonlinpos0", day, ".mat", sep = "")))

position <- position$linpos[[day]][[1]][[epoch]][[1]][,, 1]$statematrix[,, 1]
vel <- abs(position$linearVelocity[, 1])  # animal's linearized velocity
time_vel <- position$time  # time idx for velocity
plot(time_vel, vel, type = "l", xlim = c(min(time_vel), max(time_vel)))
n <- length(vel)  # n is the velocity data size

### Read animal's linearized trajecotry generated by Ken, and clean them
data <- read.delim(here("Raw-Data", "Bond",
                        paste("bond0", day, "0", epoch, ".dat", sep = "")),
                              header = F, sep = " ")
lin_position <- data[, 1] * 60
range(lin_position)  # expand the position to range [-360, 360]
lin_position[lin_position > 360] <- 360  # up-bound the position
lin_position[lin_position < (-360)] <- -360  # lower-bound the position
lin_pos <- lin_position
for (i in 1:length(lin_pos)) {
  if (abs(lin_pos[i]) > 180) {
    lin_pos[i] <- (lin_pos[i] > 0) * (360 - abs(lin_pos[i]))
  }
}
x <- as.numeric(lin_pos)
range(x)  # x is rat's linearized position


### Fit AR(1) model for movement during exploration, ie, velocity > 4cm/s
idx <- (vel[-1]) > 4  # idx for active exploration
yy <- (x[2:n])[idx]  # X_t
xx <- (x[1:(n - 1)])[idx]  # X_{t-1}
fit_position <- lm(yy ~ xx - 1)
# sigma at original rate, 30 Hz
sigma_30 <- sqrt(sum(fit_position$residuals ^ 2) /
                 fit_position$df.residual)
alpha_30 <- as.numeric(fit_position$coefficients)

#### Transfer to new frequency rate, 500 Hz.
alpha_500 <- (alpha_30 ^ 30) ^ (1 / 500)  # freq = 500 Hz
sigma_500 <- (sqrt( (1 - alpha_500 ^ 2) * (1 - alpha_30 ^ (30 * 2)) /
                  (1 - alpha_30 ^ 2) / (1 - alpha_500 ^ (500 * 2))) *
              sigma_30)
# Model at faster time rate, 20 times
alpha_25 <- (alpha_30 ^ 30) ^ (1 / 25)  # 500Hz to 25Hz, 20 times faster
sigma_25 <- sqrt( (1 - alpha_25 ^ 2) * (1 - alpha_30 ^ 60) /
                 (1 - alpha_30 ^ 2) / (1 - alpha_25 ^ 30)) *
  sigma_30
sigma_25 <- sqrt( (1 - alpha_25 ^ 2) / (1 - alpha_30 ^ 2)) * sigma_30

#### Now define the state transition matrix (x_transition_0)_ij = p(x_t=x_i|x_t-1 =
#### xj, I_t =0) (x_transition_1)_ij = p(x_t=x_i|x_t-1 = xj, I_t =1, I_t-1 =1)
x_grid <- seq(min(x), max(x), by = by)
m <- length(x_grid)

x_transition_0 <- matrix(0, m, m)
for (i in 1:m) {
  x_transition_0[, i] <- (dnorm(x_grid, mean = x_grid[i], sd = sigma_500) /
                          sum(dnorm(x_grid, mean = x_grid[i],
                                    sd = sigma_500) * by))
}
x_transition_1 <- matrix(0, m, m)
for (i in 1:m) {
  x_transition_1[, i] <- (dnorm(x_grid, mean = x_grid[i], sd = sigma_25) /
                          sum(dnorm(x_grid, mean = x_grid[i],
                                    sd = sigma_25) * by))
}

# Uniform distribution during transition state
x_transition_0to1 <- matrix(1 / round(max(x)) / by, m, m)




## 1.2 read ad hoc replay state from ripple threshold method, consider the
## velocity threshold (4 cm/s)

### Perform interpolation for rat's velocity, freq = 30Hz to 500Hz
n <- floor(diff(range(time_vel)) * freq) + 1
vel_1 <- approx(time_vel, vel, n = n)
time_vel_1 <- vel_1$x
vel_1 <- vel_1$y
summary(time_vel_1)
#### Perform interpolation for rat's trajectory, freq = 30Hz to 500Hz
x <- approx(time_vel, lin_pos, n = n)$y

## 1.3 read ripple state, and consider velocity threshold
data0 <- readMat(here("Raw-Data", "Bond", paste("bonripplescons0", day, ".mat", sep = "")))
ripple <- data0$ripplescons[[day]][[1]][[epoch]][[1]][[1]][[1]][,, 1]
#### day-epoch-1 for CA1, day-epoch-2:5 are data for onther brain regions
ripple$tetlist  # 3, 5, 12, 14, 24, 29
x_1 <- ripple$starttime  #start time of ripples
x_2 <- ripple$endtime  #end time of ripples
idx <- rep(FALSE, length(x_1))
for (i in 1:length(x_1)) {
  temp1 <- round( (x_1[i] - time_vel[1]) * freq) + 1
  temp2 <- round( (x_2[i] - time_vel[1]) * freq) + 1
  idx[i] <- max(vel_1[temp1:temp2]) <= 4
}
sum(idx)  # 254
x_1 <- x_1[idx]
x_2 <- x_2[idx]


### Build indicator function for ripple state, denoted as I_t
x1 <- round( (x_1 - time_vel[1]) * freq) + 1
x2 <- round( (x_2 - time_vel[1]) * freq) + 1
N <- length(x_1)
I <- rep(0, n)
for (i in 1:N) {
  I[x1[i]:(x2[i])] <- 1
}


## 1.3 Read LFP data Read one channel to check detial
data0 <- readMat(here("Raw-Data", "Bond",
                      paste("bonripplescons0", day, ".mat", sep = "")))
ripple <- data0$ripplescons[[day]][[1]][[epoch]][[1]][[1]][[1]][,, 1]
#### day-2-1 for CA1, day-2-2:5 are data for onther brain regions
idx <- c(ripple$tetlist)  # idx=c(3,5,12,14,24,29) 6 tetrode

#LFp of rat Bond, on day 3, epoch 2, tetrode 3
LFP <- readMat(here("Raw-Data", "Bond", "EEG", "boneeg03-2-03.mat"))
y_1 <- LFP$eeg[[day]][[1]][[epoch]][[1]][[3]][[1]][,, 1]$data
starttime <- LFP$eeg[[day]][[1]][[epoch]][[1]][[3]][[1]][,, 1]$starttime
length_LFP <- length(y_1)
rm(y_1)
y <- matrix(0, length(idx), length_LFP)
endtime <- starttime + (length_LFP - 1) / LFP_SAMPLING_FREQUENCY


### Read data from tetrode c(3, 5, 12, 14, 24, 29)
data <- readMat(here("Raw-Data", "Bond", "EEG", "boneeg03-2-03.mat"))
LFP <- LFP$eeg[[day]][[1]][[epoch]][[1]][[3]][[1]][,, 1]
y[1, ] <- LFP$data
LFP <- readMat(here("Raw-Data", "Bond", "EEG", "boneeg03-2-05.mat"))
LFP <- LFP$eeg[[day]][[1]][[epoch]][[1]][[5]][[1]][,, 1]
y[2, ] <- LFP$data
LFP <- readMat(here("Raw-Data", "Bond", "EEG", "boneeg03-2-12.mat"))
LFP <- LFP$eeg[[day]][[1]][[epoch]][[1]][[12]][[1]][,, 1]
y[3, ] <- LFP$data
LFP <- readMat(here("Raw-Data", "Bond", "EEG", "boneeg03-2-14.mat"))
LFP <- LFP$eeg[[day]][[1]][[epoch]][[1]][[14]][[1]][,, 1]
y[4, ] <- LFP$data
LFP <- readMat(here("Raw-Data", "Bond", "EEG", "boneeg03-2-24.mat"))
LFP <- LFP$eeg[[day]][[1]][[epoch]][[1]][[24]][[1]][,, 1]
y[5, ] <- LFP$data[1:dim(y)[2]]
LFP <- readMat(here("Raw-Data", "Bond", "EEG", "boneeg03-2-29.mat"))
LFP <- LFP$eeg[[day]][[1]][[epoch]][[1]][[29]][[1]][,, 1]
y[6, ] <- LFP$data[1:dim(y)[2]]



###########################################
# 2   Encoding part
###########################################

## &2.1 Fit P(v_t|v_{t-1},I_t=1), in replay state
idx <- I[2:n]
x <- (vel_1[1:(n - 1)])[idx > 0]  # v_{t-1}
y <- vel_1[2:n][idx > 0]  # v_t
sigma1 <- sd(y - x)
alpha1 <- 1  # random walk
mu_1 <- vel_1[1:(n - 1)]
mu_1[mu_1 < 0] <- 0

# log_likelihood
log_p_v_1 <- -log(sigma1) - 0.5 * (vel_1[2:n] - mu_1) ^ 2 / sigma1 ^ 2

### Fit P(v_t|v_{t-1},I_t=1), out of replay state and no active exploration
idx <- I[2:n]
x <- (vel_1[1:(n - 1)])[idx < 1]
y <- vel_1[2:n][idx < 1]
idx <- y <= 4
x <- x[idx]
y <- y[idx]
sigma0 <- sd(y - x)
mu_0 <- vel_1[1:(n - 1)]
log_p_v_0 <- -log(sigma0) - 0.5 * (vel_1[2:n] - mu_0) ^ 2 / sigma0 ^ 2

### log_likelihood ratio
l_vel <- log_p_v_1 - log_p_v_0
time <- time_vel_1
l_vel[vel_1 > 4] <- -vel_1[vel_1 > 4]
# Here the setting is a little artiticial,due to subjective understand
# about the data


## & 2.2 Fit p(I_t|I_t-1,v_t-1), replay state transition modeling

I_y <- I[-1]  # time t
I_x <- I[-n]  # time t-1
xx <- vel_1[-n]  # time t-1

#### Normalized histogram of ripple state versus speed, I_{t-1} = 0
par(mfrow = c(2, 2))
temp <- xx < 6 & I_x < 1
I_t <- I_y[temp]
vel_0 <- xx[temp]
bins <- seq(0, 6, by = 0.2)
spikehist <- hist(vel_0[I_t > 0], breaks = bins, plot = F)
occupancy <- hist(vel_0, breaks = bins, plot = F)
norm_spike <- spikehist$counts / occupancy$counts
norm_spike[is.na(norm_spike)] <- 0
plot(bins[-1], norm_spike, type = "n", xlab = expression(v[t - 1](cm / s)),
     ylab <- "Ripple state prop", ylim = range(norm_spike) * 1.2)
title(main = expression(I[t - 1] == 1))
for (i in 1:length(bins)) {
  segments(bins[i], 0, bins[i], norm_spike[i], col = 1, lwd = 4)
}

#### I_t = 1
temp <- xx < 6 & I_x > 0
I_t <- I_y[temp]
vel_0 <- xx[temp]
bins <- seq(0, 6, by = 0.2)
spikehist <- hist(vel_0[I_t > 0], breaks = bins, plot = F)
occupancy <- hist(vel_0, breaks = bins, plot = F)
norm_spike <- spikehist$counts / occupancy$counts
norm_spike[is.na(norm_spike)] <- 0
plot(bins[-1], norm_spike, type = "n", xlab = expression(v[t - 1](cm / s)),
     ylab = "Ripple state prop", ylim = range(norm_spike) * 1.2)
title(main = expression(I[t - 1] == 1))
for (i in 1:length(bins)) {
  segments(bins[i], 0, bins[i], norm_spike[i], col = 1, lwd = 4)
}

# logistic regression fit, with natural splines
fit12 <- glm(I_y ~ I_x + bs(xx, knots = c(1, 2, 3, 20)),
             family = binomial(link = "logit"))

# p(I_t|I_t-1,v_t-1);t=2:n
p_I_1 <- predict(fit12, data.frame(I_x = 1, xx = xx))  #I_t-1=1
p_I_0 <- predict(fit12, data.frame(I_x = 0, xx = xx))  #I_t-1=0
p_I_1 <- exp(p_I_1) / (1 + exp(p_I_1))
p_I_0 <- exp(p_I_0) / (1 + exp(p_I_0))  # predicted probability


# plot out fitted model
x_grid <- seq(0, 6, by = 0.1)
y_p <- predict(fit12, data.frame(I_x = 0, xx = x_grid), se.fit = TRUE)
y_0 <- exp(y_p$fit) / (1 + exp(y_p$fit))
plot(x_grid, y_0, type = "l", col = "red", xlim = c(0, 6),
     main = expression(I[t - 1] == 0), xlab = expression(v[t - 1](cm / s)),
     ylab = expression(p(I[t] == 1)))
y1 <- exp(y_p$fit + 2 * y_p$se.fit) / (1 + exp(y_p$fit + 2 * y_p$se.fit))
names(y_p)
lines(x_grid, y1, lty = 2)
y2 <- (exp(y_p$fit - 1.96 * y_p$se.fit) /
       (1 + exp(y_p$fit - 1.96 * y_p$se.fit)))
lines(x_grid, y2, lty = 2)

y_p <- predict(fit12, data.frame(I_x = 1, xx = x_grid), se.fit = TRUE)
y_0 <- exp(y_p$fit) / (1 + exp(y_p$fit))
plot(x_grid, y_0, type = "l", col = "red", xlim = c(0, 6),
     ylim = c(0, 1.1), main = expression(I[t - 1] == 1),
     xlab = expression(v[t - 1](cm / s)), ylab = expression(p(I[t] == 1)))
y1 <- exp(y_p$fit + 2 * y_p$se.fit) / (1 + exp(y_p$fit + 2 * y_p$se.fit))
names(y_p)
lines(x_grid, y1, lty = 2)
y2 <- (exp(y_p$fit - 1.96 * y_p$se.fit) /
       (1 + exp(y_p$fit - 1.96 * y_p$se.fit)))
lines(x_grid, y2, lty = 2)  # up and lower bound


## 2.3 Spectral regression p(Y_f|I_t)

### 2.3.1 Calculate spectral power of LFP Y_f, in 150-250 Hz

starttime <- as.numeric(starttime)
window_length <- 30  # 30/1.5=20 ms in time
win_num <- floor(100 * window_length / LFP_SAMPLING_FREQUENCY)

idx <- ceiling( (range(time_vel_1) - c(starttime)) *
               LFP_SAMPLING_FREQUENCY) + 1
y_vel <- lfps[, idx[1]:idx[2]]  # LFP
Y_f <- matrix(0, dim(y_vel)[1], (dim(y_vel)[2]) %/% 30)  # 6 * 46048
idx <- c(1:dim(Y_f)[2])
for (m in 1:dim(Y_f)[1]) {
  Y <- y_vel[m, ]
  for (i in 1:dim(Y_f)[2]) {
    m1 <- spec.mtm(Y[(i - 1) * 30 + 1:30], nw = win_num,
                   k = 2 * win_num - 1, nFFT = 150, log = "no", plot = F,
                   deltat = 1 / LFP_SAMPLING_FREQUENCY)
    # nw is time-bandwidth, k is number of tapers set nFFT = 150, then by=10;
    # nFTT=30, then by=50. (freq # -1)*2 = nFTT
    temp <- m1$spec[m1$freq <= 200 & m1$freq >= 200]
    Y_f[m, i] <- temp
  }
}
sum(is.na(Y_f))

Y_f <- as.numeric(Y_f)
Y_f <- matrix(Y_f, nrow = 6)
Y_f <- log(Y_f)  # in the log scale



## 2.3.2 Calculate spectral power in 2 states: 0 and 1 ##
P_0 <- matrix(0, 6, sum(I < 1) + 1000)  # sum(I<1) = 45543
P_1 <- matrix(0, 6, sum(I > 0) + 500)  # sum(I>0) = 1656
p_0 <- rep(1, dim(P_0)[2])
p_1 <- rep(1, dim(P_1)[2])
x_2 <- c(starttime, x_2)
x_2 <- x_2[-c(1:(length(x_2) - length(x_1)))]
x_2 <- c(starttime, x_2)

for (m in 1:dim(y)[1]) {
  k1 <- k0 <- 1
  Y <- y[m, ]
  for (i in 1:length(x_1)) {
    # length of in state
    l_1 <- (x_2[-1] - x_1)[i] * LFP_SAMPLING_FREQUENCY
    # length of out state
    l_2 <- (x_1 - x_2[-length(x_2)])[i] * LFP_SAMPLING_FREQUENCY

    N_1 <- floor(l_1 / window_length)  # number of windows in state
    N_2 <- floor(l_2 / window_length)  # number of windows out state

    if (N_1 > 0) {
      # calculate the average power for in state
      for (j in 1:(N_1 - 1)) {
        m1 <- spec.mtm(Y[(x_1[i] - starttime) * LFP_SAMPLING_FREQUENCY +
                       (j - 1) * window_length + 1:window_length],
                       nw = win_num, k = 2 * win_num - 1, nFFT = 150,
                       log = "no", plot = FALSE,
                       deltat = 1 / LFP_SAMPLING_FREQUENCY)
        # nFFT = 150, by=10; nFTT=30, by=50. (freq # -1)*2 = nFTT
        temp <- m1$spec[m1$freq <= 200 & m1$freq >= 200]
        # p_1=c(p_1, temp[!is.na(temp)] )
        p_1[k1] <- temp
        k1 <- k1 + 1
      }

      win_num_1 <- floor(100 * (l_1 - (N_1 - 1) * window_length) /
                         LFP_SAMPLING_FREQUENCY)
      m1 <- spec.mtm(Y[(x_1[i] - starttime) * LFP_SAMPLING_FREQUENCY +
                     ( (N_1 - 1) * window_length + 1):l_1], nw = win_num_1,
                     k = floor(2 * win_num_1 - 1), nFFT = 150,
                     log = "no", plot = F,
                     deltat = 1 / LFP_SAMPLING_FREQUENCY)
      temp <- m1$spec[m1$freq <= 200 & m1$freq >= 200]
      # p_1=c(p_1, temp[!is.na(temp)] )
      p_1[k1] <- temp
      k1 <- k1 + 1
    }
    if (N_2 > 0) {
      # calculate the average power for out state
      for (j in 1:(N_2 - 1)) {
        m1 <- spec.mtm(Y[(x_2[i] - starttime) * LFP_SAMPLING_FREQUENCY +
                       (j - 1) * window_length + 1:window_length],
                       nw = win_num, k = 2 * win_num - 1, nFFT = 150,
                       log = "no", plot = F,
                       deltat = 1 / LFP_SAMPLING_FREQUENCY)
        temp <- m1$spec[m1$freq <= 200 & m1$freq >= 200]
        # p_0=c(p_0, temp[!is.na(temp)] )
        p_0[k0] <- temp
        k0 <- k0 + 1
      }

      win_num_1 <- floor(100 * (l_2 - (N_2 - 1) * window_length) /
                         LFP_SAMPLING_FREQUENCY)
      m1 <- spec.mtm(Y[(x_2[i] - starttime) * LFP_SAMPLING_FREQUENCY +
                     ( (N_2 - 1) * window_length + 1):l_2],
                     nw = win_num_1, k = floor(2 * win_num - 1),
                     nFFT = 150, log = "no", plot = F,
                     deltat = 1 / LFP_SAMPLING_FREQUENCY)
      temp <- m1$spec[m1$freq <= 200 & m1$freq >= 200]
      # p_0=c(p_0, temp[!is.na(temp)] )
      p_0[k0] <- temp
      k0 <- k0 + 1
    }
  }
  P_0[m, ] <- p_0
  P_1[m, ] <- p_1
}
P_1 <- P_1[, 1:(k1 - 1)]
P_0 <- P_0[, 1:(k0 - 1)]
P_1 <- log(P_1)
P_0 <- log(P_0)


### 2.3.3 Likelihood for LFP, using kernel density estimate
L <- dim(Y_f)[2]
f_1 <- f_0 <- seq(L)
p <- dim(Y_f)[1]

sigma_1 <- apply(P_1, 1, sd)
H_1 <- (diag(sigma_1) * (4 / (p + 2) / n) ^ ( 1 / (p + 4))) ^ 2
sigma_0 <- apply(P_0, 1, sd)
H_0 <- (diag(sigma_0) * (4 / (p + 2) / n) ^ ( 1 / (p + 4))) ^ 2

for (j in 1:L) {
  # each row of matrix
  f_1[j] <- mean(dmvnorm(t(P_1), mean = Y_f[, j], sigma = H_1))
}
for (j in 1:L) {
  # each row of matrix
  f_0[j] <- mean(dmvnorm(t(P_0), mean = Y_f[, j], sigma = H_0))
}
summary(log(f_1 / f_0))

## & 2.4 GLM for spiking information
cl <- makeCluster(7, type = "SOCK")  # 7 - number of cores
registerDoSNOW(cl)  # Register back end Cores for Parallel Computing


# Set bandwidth parameters for kernel functions
B_x <- b_x <- 360 * 0.15 * 0.1  # 1.5% of linear track length
B_m <- diag(rep(20, 4))
T <- diff(range(time))  # duration of the experiment

#### 2.4.1 Read unsorted spike data

lambda0_all <- lambda1_all <- NULL  # joint mark conditional intensity
Lambda0_all <- Lambda1_all <- NULL  # marginal intensity
# tetrode index for Bond, day3, epoch2
tetrode_idx <- c(1:5, 7:8, 10:14, 17:25, 27:29)

x_grid <- seq(-180, 180, by = 1)
m <- length(x_grid)
x_0 <- x[I < 1]


x_0_30Hz <- lin_pos[I[seq(1, n, by = freq / 30)] < 1]
x_0_30Hz <- x_0_30Hz[!is.na(x_0_30Hz)]
ptm <- proc.time()
stopCluster(cl)  # undo the parallel processing setup
cl <- makeCluster(3, type = "SOCK")  # 3 - number of cores
registerDoSNOW(cl)  # Register back end Cores for Parallel Computing
denom_grid_0 <- 1 / 30 * foreach(i = 1:m, .combine = "c") %dopar% {
  sum(dnorm(x_0_30Hz, mean = x_grid[i], sd = b_x))
}
proc.time() - ptm
head(denom_grid_0)

ptm <- proc.time()
denom_grid_0 <- numeric(m)
for (i in 1:m) {
  denom_grid_0[i] <- 1 / freq * sum(dnorm(x_0, mean = x_grid[i], sd = b_x))
}
proc.time() - ptm



x_1 <- x[I > 0]

stopCluster(cl)  # undo the parallel processing setup
cl <- makeCluster(3, type = "SOCK")  # 3 - number of cores
registerDoSNOW(cl)  # Register back end Cores for Parallel Computing
denom_grid_1 <- 1 / freq * foreach(i = 1:m, .combine = "c") %dopar% {
  sum(dnorm(x_1, mean = x_grid[i], sd = b_x))
}

ptm <- proc.time()  # Record the starttime
# for (tetrode in 1:1){
for (tetrode in tetrode_idx) {

  if (tetrode < 10) {
    idx <- paste(0, tetrode, sep = "")
  }
  if (tetrode >= 10) {
    idx <- paste(tetrode, sep = "")
  }
  # data path
  path1 <- here("Raw-Data", "Bond", "EEG",
                paste("bonmarks0", day, "-", idx, ".mat", sep = ""))
  data <- readMat(path1)



  Time <- data$filedata[,, 1]$params[, 1]  # Recorded spike times
  print(c(tetrode))

  # It also has the (x,y), 2-d positions
  Spike_time <- Time / 10 ^ 4
  idx <- (Spike_time >= min(time)) & (Spike_time <= max(time))
  # sum(idx)/length(idx) # 13.4%
  Spike_time <- Spike_time[idx]  #length(Spike_time) # # of spikes
  M <- data$filedata[,, 1]$params[idx, 2:5]  # mark space: M, dim = N * 4
  rm(data)

  N <- numeric(n)
  temp <- (Spike_time - min(time)) * 500
  for (i in temp) {
    N[i] <- N[i] + 1
  }





  ##########################################
  lambda0 <- numeric(n)
  idx <- I[(Spike_time - min(time)) * 500] < 1  # idx for non-replay state
  # non-ripple period
  x_s_0 <- approx(time_vel, lin_pos, xout = Spike_time[idx])$y

  M_0 <- M[idx, ]  # Marked space during non-replay
  N_0 <- N[I < 1]


  # calculate marginal intensity
  Lambda_grid <- numeric(m)

  stopCluster(cl)  # undo the parallel processing setup
  cl <- makeCluster(3, type = "SOCK")  # 3 - number of cores
  registerDoSNOW(cl)  # Register back end Cores for Parallel Computing

  num <- foreach(i = 1:m, .combine = "c") %dopar% {
    sum(dnorm(x_s_0, x_grid[i], sd = B_x))
  }

  Lambda_grid <- num / denom_grid_0
  # Marginal intensity rate
  Lambda0 <- Lambda_grid[round(x) - min(x_grid) + 1]



  idx <- c(1:n)[N > 0]  # idx for spike time



  # parallel computation
  stopCluster(cl)  # undo the parallel processing setup
  cl <- makeCluster(3, type = "SOCK")  # 3 - number of cores
  registerDoSNOW(cl)  # Register back end Cores for Parallel Computing

  num0 <- foreach(i = idx, .combine = "c", .packages = "mvtnorm") %dopar% {
    sum(dnorm(x_s_0, mean = x[i], sd = B_x) *
    dmvnorm(x = M_0, mean = M[sum(N[1:i]), ], sigma = B_m ^ 2))
  }


  denom0 <- denom_grid_0[round(x[idx]) - min(x_grid) + 1]
  # we calculate the denominator in advance
  lambda0[idx] <- N[idx] * num0 / denom0


  ##########################################
  # during replay time
  ##########################################

  lambda1 <- numeric(n)

  idx <- I[(Spike_time - min(time)) * freq] > 0
  # idx for spiking during replay state
  Lambda1 <- freq * rep(sum(N[I > 0]) / sum(I > 0), n)  # spikes per second
  x_s_1 <- approx(time_vel, lin_pos, xout = Spike_time[idx])$y
  length(x_s_1)  # in-ripple period
  x_1 <- x[I > 0]
  M_1 <- M[idx, ]  # Marked space during non-replay
  N_1 <- N[I > 0]



  idx <- c(1:n)[N > 0]  # idx for spike times

  stopCluster(cl)  # undo the parallel processing setup
  cl <- makeCluster(3, type = "SOCK")  # 3 - number of cores
  registerDoSNOW(cl)  # Register back end Cores for Parallel Computing

  num1 <- foreach(i = idx, .combine = "c", .packages = "mvtnorm") %dopar% {
    sum(dmvnorm(x = M_1, mean = M[sum(N[1:i]), ], sigma = B_m ^ 2))
  }


  # x_s_1 is the animal's position at all spike moment during replay M_1 is
  # the mark value at all spike moment during replay

  # denom1 = denom_grid_1[round(x[idx]) - min(x) +1] # This is wrong
  denom1 <- sum(I > 0) / freq
  lambda1[idx] <- N[idx] * num1 / denom1


  Lambda0_all <- rbind(Lambda0_all, Lambda0)
  lambda0_all <- rbind(lambda0_all, lambda0)
  Lambda1_all <- rbind(Lambda1_all, Lambda1)
  lambda1_all <- rbind(lambda1_all, lambda1)
  print(c(range(lambda0), range(lambda1), range(Lambda0), range(Lambda1)))
}
proc.time() - ptm


# calculate the likelihood here
ptm <- proc.time()
dt <- 1 / freq
log_p_0 <- log_p_1 <- 0
tetrode_idx <- c(1:5, 7:8, 10:14, 17:25, 27:29)  # tetrode index
# load(paste(path,'Data/unsorted spiking kernel fit Bond day3 epoch',epoch,'
# homogeneous.RData',sep=''))


k <- 1
for (tetrode in tetrode_idx) {
  if (tetrode < 10) {
    idx <- paste(0, tetrode, sep = "")
  }
  if (tetrode >= 10) {
    idx <- paste(tetrode, sep = "")
  }

  # data path
  path1 <- here("Raw-Data", "Bond", "EEG",
                paste("bonmarks0", day, "-", idx, ".mat", sep = ""))
  data <- readMat(path1)  # position on day 5

  Time <- data$filedata[,, 1]$params[, 1]  # Spike time

  # It also has the (x,y), 2-d positions
  Spike_time <- Time / 10 ^ 4
  idx <- (Spike_time >= min(time)) & (Spike_time <= max(time))
  Spike_time <- Spike_time[idx]  #length(Spike_time) # # of spikes
  N <- numeric(n)
  temp <- (Spike_time - min(time)) * freq
  for (i in temp) {
    N[i] <- N[i] + 1
  }
  print(c(range(lambda0_all[k, ]),
          range(lambda1_all[k, ]),
          range(Lambda0_all[k, ]),
          range(Lambda1_all[k, ])))

  if (sum(is.na(
      c(range(lambda0_all[k, ]),
        range(lambda1_all[k, ]),
        range(Lambda0_all[k, ]),
        range(Lambda1_all[k, ])))) == 0) {
    log_p_0 <- log_p_0 + (-Lambda0_all[k, ] * dt + N * log(lambda0_all[k, ]
                          * dt + 1e-200))
    log_p_1 <- log_p_1 + (-Lambda1_all[k, ] * dt + N * log(lambda1_all[k, ]
                          * dt + 1e-200))
  }
  k <- k + 1
}
L1 <- exp(log_p_1 - log_p_0)
time <- time_vel_1




#################################################
# 4. Decoding part, p(I_t|,y_{1:t},v_{1:t})
#################################################
vel_idx <- 0  # whether we consider p(v_t|v_{t-1}, I_t)
q_LFP <- rep(0, n)  # posterior probability given LFP and velocity
for (i in 2:n) {
  temp <- i %% 10
  q1 <- (exp(l_LFP[i %/% 10 + 1] * (temp == 0)) *
         exp(l_vel[i - 1] * vel_idx) *
         (p_I_0[i - 1] * (1 - q_LFP[i - 1]) + p_I_1[i - 1] * q_LFP[i - 1]))
  q2 <- ( (1 - p_I_0[i - 1]) * (1 - q_LFP[i - 1]) + (1 - p_I_1[i - 1]) *
         q_LFP[i - 1])
  q_LFP[i] <- q1 / (q1 + q2)
}
summary(q_LFP)

### LFP, spiking and velocity
vel_idx <- 0
q_remote <- numeric(n)
for (i in 2:n) {
  temp <- i %% 10
  q1 <- (exp(l_LFP[i %/% 10 + 1] * (temp == 0)) *
         exp(l_vel[i - 1] * vel_idx) * L1[i] *
         (p_I_0[i - 1] * (1 - q_remote[i - 1]) + p_I_1[i - 1] *
          q_remote[i - 1]))
  q2 <- ( (1 - p_I_0[i - 1]) * (1 - q_remote[i - 1]) + (1 - p_I_1[i - 1])
         * q_remote[i - 1])
  q_remote[i] <- q1 / (q1 + q2)
}
summary(q_remote)

### spiking and velocity only
vel_idx <- 0
q_spiking <- numeric(n)
for (i in 2:n) {
  temp <- i %% 10
  q1 <- exp(l_vel[i - 1] * vel_idx) * L1[i] * (p_I_0[i - 1] * (
      1 - q_spiking[i - 1]) + p_I_1[i - 1] * q_spiking[i - 1])
  q2 <- ( (1 - p_I_0[i - 1]) * (1 - q_spiking[i - 1]) + (1 - p_I_1[i - 1])
         * q_spiking[i - 1])
  q_spiking[i] <- q1 / (q1 + q2)
}
summary(q_spiking)
